---
title: "Foundations for ML and Neural Networks"
description: | 
  Notes for the morning session for day 2 of NAAMII's Winter School on AI.
site: distill::distill_website
listing: posts
---

## Learning Outcomes

### Machine Learning Foundations

1. Given a problem description, determine features that may be relevant, including those directly present in the raw data and those that must be constructed.
2. Given a problem description, determine an appropriate response variable.
3. Design a model evaluation scheme for a specific problem / model context, keeping in mind the dangers of overfitting and the bias-variance trade-off.
4. Given a covariate / response pair, use visualization and summary statistics to identify preprocessing or transformation methods that may improve downstream model performance.
5. Discuss the relative merits of linear, sparse, and tree-based methods in a particular problem setting, and prepare code that implements them appropriately.
6. Use model summaries and data visualization to summarize the important features in a model and note areas for potential improvement.

### Neural Networks Foundations

1. Given a numeric covariate matrix and response variable, use pytorch to train a nonlinear regressor that minimizes L2 loss.
2. Given a collection of PNG files and class labels, use pytorch to train an image classifier and produce predicted labels for a new unlabeled set.
3. Sketch the relationships between and the roles of different components of a deep learning workflow, including the dataloader, the model, the optimizer, the loss function, and inference routines.
4. Be able to explain the mechanics of backpropagation and relate it to the overall  process of training deep learning models.
5. Given a contextual problem description, discuss the relative merits of deep vs. non-deep learning methods.
6. Evaluate the relative value of using pretrained weights, and being able to apply them in an original problem context.


## Outline